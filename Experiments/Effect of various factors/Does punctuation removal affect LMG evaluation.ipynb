{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1bf495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "preds=[]\n",
    "refs=[]\n",
    "auth_1 =[]\n",
    "auth_2 = []\n",
    "auth_3 =[]\n",
    "with open('human_annotations.csv') as csvfile:\n",
    "    ader = csv.reader(csvfile)\n",
    "    for row in ader:\n",
    "        refs.append(row[1])\n",
    "        preds.append(row[0])\n",
    "        auth_1.append(row[2])\n",
    "        auth_2.append(row[3])\n",
    "        auth_3.append(row[4])\n",
    "        \n",
    "refs_n = refs[:100]\n",
    "preds_n = preds[:100]\n",
    "\n",
    "auth_1 = auth_1[:100]\n",
    "for i in range(0, len(auth_1)):\n",
    "    auth_1[i] = int(auth_1[i])\n",
    "#print(auth_1)\n",
    "\n",
    "auth_2 = auth_2[:100]\n",
    "for i in range(0, len(auth_2)):\n",
    "    auth_2[i] = int(auth_2[i])\n",
    "#print(auth_2)\n",
    "\n",
    "auth_3 = auth_3[:100]\n",
    "for i in range(0, len(auth_3)):\n",
    "    auth_3[i] = int(auth_3[i])\n",
    "#print(auth_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8407d9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Noting', 'Polish', 'add known user', ' refactor JDBCXABackendDataSourceFactory', 'kryo updated', 'Update CHANGES', 'Update ISSUETEMPLATE', 'change name selectorderbywithtablestartablename for parser', 'Update CHANGES', 'Remove unused property', 'Fix nullness test', 'Built the latest snapshot', 'Add Gradle Wrapper Validation GitHub Action', 'typo ', 'fixed for issue', 'Remove tmp directory', 'PetSoar  not PetStore', ' refactor Int2BinaryProtocolValueTest', ' refactor TimeBinaryProtocolValueTest', 'modifty the logview', 'add setup  ', 'Mock data tool icon', 'RAT 0  11', ' py  Remove unused import', 'RedissonRedLock unlock fixed ', 'Fix typo in documentation', 'Simulate false unit test', 'Fix JUnit reports location', 'bug fixed for SQLInListExpr  issue 1076', 'Add  since for Enums  getField ', 'SDK  Add missing  gitignore', 'Reintroduce  Add Gradle Wrapper Validation GitHub Action ', 'DBeaver perspective config', 'added chain of responsibility class diagram', 'Update README  ', 'Update ProjectsusingMPAndroidChart  txt', ' DOCS  fixed typo in date  format  asciidoc', 'SimonStewart  Backward compatibility fix', ' DOCS  Fixed typo ', 'Mute LicenseDocumentationIT  testGetLicense  ', 'Add Binary repo for jvmci', 'Fix typo ', 'Upgrade to netty 4  0  8  Final', 'Remove todo in StringEncoder  ', 'Transfer status fix', ' fixed  dispose for spritebatch  ugh   ', 'DanielWagnerHall  Removing trailings space', 'Fix GPLv2 license URL ', 'Update allocation  asciidoc', 'EQL  Fix async EQL Rest test  ', 'SimonStewart  Officially target Java6 ', 'Upgrade to Plexus Utils 3  0  24', 'Backport missing 3rd party starter reference', 'Fix reported leaks', 'NPE fix', 'Retain old parameter type ', '1  3  0  SNAPSHOT', 'Fix target label ', 'Use defaultvisibility instead of visibility in package  ', 'Give a name to the Bazel workspace', ' DOCS  Fixed bad cross doc link ', 'Update script  security to 1  65', ' grid  Stop driver server when session is over  Fixes', ' fixed  Bug in Mesh  setIndices    had to clear buffer first ', 'Switch to parametric CI jobs  ', 'Remove debugging println from API JAR task', 'Fix git log check start date', ' FLINK  5050   build  Remove transitive JSON  org dependency', ' TEST  cat  allocation  One index  allow leading spaces in unassigned shards lines', 'remove blank line ', 'add mysql dependency', 'Update overlay revision ', 'RS close fix', 'Add missing title', 'Add memory benchmarks to BenchTest task', 'fixed a horrible horrible memory leak ', 'Fixed IndependentScaledNumericValue ', ' Docs  Remove boost parameter from intervals  query example  ', 'Set correct github tag for generated docs', 'fixed typo', 'removing htmlunit driver from java pom file  it  s external now', 'Fix avatar location in a group conversation ', ' FIXED JENKINS  8892  update changelog', 'Add testcase for float to i32 bitcast', ' tests  Revert accidentally committed log level change for tests', ' travis  Fix some ruby dependencies for travis  see', ' DOCS  Update term vectors snippet to prevent CI failure  ', 'SimonStewart  Green bar with HtmlUnit ', 'upgrade maven  antrun  extended  plugin 1  39   1  42', 'py  use dict getter to retrieve binary', 'Add logging information to the user  s guide', 'Adjust skip version for shrink index test', 'Remove a  since tag that was just plain false', 'test  wait only for the index test1', 'fix compile error ', 'updated version to RC2', 'Remove cruft', 'Shuffling from internal change ', 'Merge ', 'Increasing bazel test timeout']\n",
      "['Noting', 'Polish', 'add known user', ' refactor JDBCXABackendDataSourceFactory', 'kryo updated', 'Update CHANGES', 'Update ISSUETEMPLATE', 'add selectorderbywithtablestartablename', 'updated CHANGES', 'remove unused logger', 'Fix nullness error', 'Built the latest version', 'Add Gradle Wrapper validation', 'typo', 'fixed issue', 'remove nacos test', 'PetSoar ', ' refactor Int2BinaryProtocolValueTest Int2BinaryProtocolValueTest execute', ' refactor TimeBinaryProtocolValueTest TimeBinaryProtocolValueTest execute', 'fix logview bug', 'add configMapOrchestrationListener  ', 'Mock Data name fix', 'Update rat to 0  11', ' py  fix EdgeOptions', 'RedissonRedLock  sync fixed', 'Fix typo in websocket  ', 'Fix test error', 'Fix test', 'bug fixed for issue', 'Add  since annotation to Enums ', 'add  gitignore', 'Add Gradle Wrapper validation', 'Perspective  BOTTOM fix', 'added chain diagram', 'Update README  md  ', 'Merge pull request from jasta  fix  ProjectsusingMPAndroidChart', ' DOCS  Fix typo in date format docs', 'SimonStewart  Fixing the Capabilities', ' DOCS  Fix typo in setup docs', 'Mute LicensingDocumentationIT   ', 'updated jvmci import', 'Fix typo in README  md', 'Upgrade to Netty 4  0  8  Final', 'Remove TODO', 'Data transfer  changes fix', ' fixed  SpriteBatch  dispose   ', 'DanielWagnerHall  Fixing the test ', 'Update GNU import ', ' DOCS  Fix typo in allocation  asciidoc', ' Monitoring  Fix test case for test  ', 'SimonStewart  Fixing the build build ', 'Upgrade to plexus  utils 3  0  24', 'Add missing RestFB', 'Fix a bug in SnappyFramedEncoderTest', 'QM  null type fix', 'Rename setServer to setServer ', ' Gradle Release Plugin   pre tag commit   1  3  0  SNAPSHOT  ', 'Fix typo in cpp  md', 'Fix visibility of visibility in go', 'Add bazel   to WORKSPACE', ' DOCS  EQL  Update ODBC ODBC docs  ', 'Merge pull request from oleg  nenashev  script  1  65', ' grid  Fixing a bug in the DriverServiceSessionFactory stop', ' fixed  Mesh  setVertices   ', 'Add build to build CI', 'Remove unused license from plugin', 'Fix error message in args', ' FLINK  10366   batch  Add json dependency to flink  hcatalog  connectors', ' TEST  Fix cat  allocation  allocation  allocation', 'for  remove useless test case', 'add runtime  connector  java', ' ci  fix overlay build', 'SQL editor fix  fix ', 'Add Spring Integration metrics to docs', 'Add benchmark for benchmark tests ', ' FIXED HUDSON  21394 ', ' fixed  ScaledNumericValue  ScaledNumericValue ', ' DOCS  Fix typo in intervals query docs', 'Fix broken link to github  tag', 'fixed a typo in the BuildTrigger ', 'MichaelTamm  remove selenium  htmlunit  driver from java  htmlunit  driver', 'Fix crash in message message ', ' JENKINS  8905   Update changelog for JENKINS  8905', 'Add GCC test for float2i32bit i32  0', ' hotfix   tests  Fix typo in log4j  test  properties', ' ci   travis  Add gem install     version', ' DOCS  Fix typo in termvectors  asciidoc', 'SimonStewart  Fixing a typo in the formPage page', 'Merge pull request from oleg  nenashev  maven  1  42', ' py  fix binary capabilities', 'Update MyBatis  User  Guide  Guide', ' DOCS  Fix typo in shrink test', 'Remove unused  since ', 'test  fix test error', 'fix the error message in AbstractDirectory cluster directory ', 'updated to 3  0  0  RC2', 'Remove unnecessary System  err  ', 'Add a test to the testModule ', 'LinearScan  fix liveIn  liveIn ', ' bazel  Fix  bazelrc file']\n"
     ]
    }
   ],
   "source": [
    "#Reference and predicted without punctuation\n",
    "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    " \n",
    "#refs_new = []\n",
    "for i in range(len(auth_1)):\n",
    "    for ele in refs_n[i]:\n",
    "        if ele in punc:\n",
    "            refs_n[i] = refs_n[i].replace(ele, \"\")\n",
    "\n",
    "#preds_new = []\n",
    "for i in range(len(auth_1)):\n",
    "    for ele in preds_n[i]:\n",
    "        if ele in punc:\n",
    "            preds_n[i] = preds_n[i].replace(ele, \"\")\n",
    "print(refs_n)\n",
    "print(preds_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b90a3820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.75, 0.75, 0.75, 0.75, 1.0, 1.0, 0.5, 0.5, 0.75, 0.75, 0.5, 0.5, 0.5, 0.75, 0.25, 0.75, 0.75, 0.5, 0.5, 0.75, 0.75, 0.75, 0.75, 0.25, 0.75, 1.0, 0.25, 1.0, 0.75, 0.75, 0.75, 0.25, 0.75, 1.0, 0.75, 0.5, 0.75, 0.25, 0.0, 0.75, 0.5, 0.25, 1.0, 0.25, 0.5, 0.5, 0.0, 0.5, 0.5, 0.25, 0.5, 0.25, 0.25, 0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.25, 0.25, 0.5, 0.75, 0.5, 0.5, 0.25, 0.25, 0.75, 0.5, 0.5, 0.75, 0.5, 0.25, 0.25, 0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.75, 0.25, 0.5, 0.75, 0.5, 0.0, 0.0, 0.25]\n"
     ]
    }
   ],
   "source": [
    "#normalised author 1 scores\n",
    "norm_auth_1 =[]\n",
    "max1 = max(auth_1)\n",
    "min1 = min(auth_1)\n",
    "\n",
    "for a in range(len(auth_1)):\n",
    "    norm_auth_1.append((auth_1[a])/(max1))\n",
    "print(norm_auth_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deda4dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.75, 0.75, 0.75, 0.75, 1.0, 1.0, 0.25, 0.5, 0.5, 0.5, 0.25, 0.5, 0.5, 0.5, 0.0, 0.75, 0.75, 0.25, 0.25, 0.75, 0.5, 0.75, 0.5, 0.25, 0.75, 1.0, 0.0, 0.75, 0.75, 0.75, 0.75, 0.25, 0.5, 1.0, 0.5, 0.5, 0.5, 0.25, 0.0, 0.5, 0.5, 0.25, 1.0, 0.25, 0.25, 0.25, 0.0, 0.5, 0.25, 0.5, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.5, 0.5, 0.25, 0.25, 0.25, 0.25, 0.25, 0.75, 0.25, 0.5, 0.25, 0.25, 0.5, 0.5, 0.25, 0.5, 0.5, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.5, 0.5, 0.25, 0.25, 0.5, 0.25, 0.0, 0.0, 0.5]\n"
     ]
    }
   ],
   "source": [
    "#normalised author 2 scores\n",
    "norm_auth_2 =[]\n",
    "max1 = max(auth_2)\n",
    "min1 = min(auth_2)\n",
    "\n",
    "for a in range(len(auth_2)):\n",
    "    norm_auth_2.append((auth_2[a])/(max1))\n",
    "print(norm_auth_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1faac0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.75, 0.75, 0.75, 0.75, 1.0, 1.0, 0.5, 0.5, 0.75, 0.75, 0.5, 0.75, 0.5, 0.75, 0.25, 0.75, 0.75, 0.25, 0.5, 0.75, 0.75, 0.75, 0.75, 0.25, 0.75, 1.0, 0.0, 1.0, 0.75, 1.0, 0.75, 0.25, 0.75, 1.0, 0.75, 0.5, 0.75, 0.5, 0.0, 0.75, 0.5, 0.25, 1.0, 0.25, 0.5, 0.5, 0.0, 0.75, 0.5, 0.5, 0.5, 0.25, 0.25, 0.5, 0.5, 0.25, 0.5, 0.25, 0.5, 0.5, 0.5, 0.25, 0.25, 0.25, 0.5, 0.75, 0.5, 0.75, 0.25, 0.25, 0.75, 0.75, 0.5, 0.75, 0.5, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.25, 0.5, 0.75, 0.5, 0.0, 0.0, 0.25]\n"
     ]
    }
   ],
   "source": [
    "#normalised author 3 scores\n",
    "norm_auth_3 =[]\n",
    "max1 = max(auth_3)\n",
    "min1 = min(auth_3)\n",
    "\n",
    "for a in range(len(auth_3)):\n",
    "    norm_auth_3.append((auth_3[a])/(max1))\n",
    "print(norm_auth_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "878d56a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42, 1.0, 0.75, 0.75, 0.75, 0.75, 1.0, 1.0, 0.42, 0.5, 0.67, 0.67, 0.42, 0.58, 0.5, 0.67, 0.17, 0.75, 0.75, 0.33, 0.42, 0.75, 0.67, 0.75, 0.67, 0.25, 0.75, 1.0, 0.08, 0.92, 0.75, 0.83, 0.75, 0.25, 0.67, 1.0, 0.67, 0.5, 0.67, 0.33, 0.0, 0.67, 0.5, 0.25, 1.0, 0.25, 0.42, 0.42, 0.0, 0.58, 0.42, 0.42, 0.42, 0.25, 0.25, 0.33, 0.33, 0.25, 0.42, 0.33, 0.5, 0.5, 0.42, 0.33, 0.25, 0.25, 0.42, 0.75, 0.42, 0.58, 0.25, 0.25, 0.67, 0.58, 0.42, 0.67, 0.5, 0.25, 0.25, 0.25, 0.25, 0.25, 0.33, 0.42, 0.5, 0.58, 0.25, 0.42, 0.67, 0.42, 0.0, 0.0, 0.33]\n"
     ]
    }
   ],
   "source": [
    "#Average normalised author scores\n",
    "avg_norm_score = []\n",
    "for i in range(len(auth_1)):\n",
    "    avg_norm_score.append(round((norm_auth_1[i]+norm_auth_2[i]+norm_auth_3[i])/3,2))\n",
    "print(avg_norm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1f210ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ab8a41",
   "metadata": {},
   "source": [
    "# BLEU4 with punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9726fcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.57, 0.72, 0.61, 0.71, 0.69, 0.56, 0.78, 0.63, 0.31, 0.2, 0.5, 0.5, 0.39, 0.09, 0.34, 0.25, 0.18, 0.71, 0.49, 0.15, 0.04, 0.33, 0.53, 0.34, 0.35, 0.43, 0.27, 0.77, 0.47, 0.62, 0.47, 0.48, 0.56, 0.26, 0.36, 0.91, 0.1, 0.44, 0.6, 0.51, 0.0, 0.53, 0.37, 0.4, 0.8, 0.13, 0.1, 0.14, 0.16, 0.26, 0.21, 0.42, 0.17, 0.27, 0.27, 0.37, 0.24, 0.12, 0.31, 0.13, 0.32, 0.32, 0.22, 0.11, 0.36, 0.14, 0.16, 0.44, 0.0, 0.48, 0.28, 0.25, 0.24, 0.49, 0.13, 0.5, 0.53, 0.25, 0.22, 0.29, 0.34, 0.3, 0.24, 0.19, 0.31, 0.21, 0.26, 0.16, 0.5, 0.2, 0.0, 0.0, 0.24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samri\\anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\samri\\anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\samri\\anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "bleu4_pr=[]\n",
    "for i in range(len(auth_1)):\n",
    "    bleu4_pr.append(round(sentence_bleu([refs_n[i]], preds_n[i]),2))\n",
    "print(bleu4_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c9de0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.57, 0.72, 0.61, 0.71, 0.69, 0.56, 0.78, 0.63, 0.31, 0.2, 0.5, 0.5, 0.39, 0.09, 0.34, 0.25, 0.18, 0.71, 0.49, 0.15, 0.04, 0.33, 0.53, 0.34, 0.35, 0.43, 0.27, 0.77, 0.47, 0.62, 0.47, 0.48, 0.56, 0.26, 0.36, 0.91, 0.1, 0.44, 0.6, 0.51, 0.0, 0.53, 0.37, 0.4, 0.8, 0.13, 0.1, 0.14, 0.16, 0.26, 0.21, 0.42, 0.17, 0.27, 0.27, 0.37, 0.24, 0.12, 0.31, 0.13, 0.32, 0.32, 0.22, 0.11, 0.36, 0.14, 0.16, 0.44, 0.0, 0.48, 0.28, 0.25, 0.24, 0.49, 0.13, 0.5, 0.53, 0.25, 0.22, 0.29, 0.34, 0.3, 0.24, 0.19, 0.31, 0.21, 0.26, 0.16, 0.5, 0.2, 0.0, 0.0, 0.24]\n"
     ]
    }
   ],
   "source": [
    "norm_bleu4_pr = []\n",
    "\n",
    "max_b4=max(bleu4_pr)\n",
    "min_b4=min(bleu4_pr)\n",
    "\n",
    "for a in range(len(bleu4_pr)):\n",
    "    norm_bleu4_pr.append(round(((bleu4_pr[a])/(max_b4)),2))\n",
    "print(norm_bleu4_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eb80626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmans correlation coefficient: 0.707\n",
      "correlated (reject H0) p=0.000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# calculate spearman's correlation\n",
    "coef, p = spearmanr(norm_bleu4_pr, avg_norm_score)\n",
    "print('Spearmans correlation coefficient: %.3f' % coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "else:\n",
    "\tprint('correlated (reject H0) p=%.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5442ca1c",
   "metadata": {},
   "source": [
    "# BLEU4 without punctuation removal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3854744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62, 0.72, 0.61, 0.71, 0.69, 0.56, 0.61, 0.63, 0.31, 0.24, 0.5, 0.5, 0.39, 0.13, 0.34, 0.29, 0.26, 0.7, 0.49, 0.15, 0.04, 0.32, 0.54, 0.34, 0.32, 0.43, 0.27, 0.71, 0.47, 0.61, 0.49, 0.52, 0.55, 0.26, 0.37, 0.92, 0.08, 0.42, 0.57, 0.52, 0.0, 0.52, 0.36, 0.42, 0.79, 0.13, 0.1, 0.13, 0.17, 0.27, 0.21, 0.39, 0.18, 0.29, 0.26, 0.38, 0.31, 0.11, 0.31, 0.13, 0.35, 0.32, 0.22, 0.1, 0.35, 0.13, 0.16, 0.44, 0.0, 0.46, 0.27, 0.25, 0.23, 0.44, 0.13, 0.49, 0.53, 0.28, 0.25, 0.3, 0.35, 0.26, 0.21, 0.16, 0.32, 0.24, 0.27, 0.17, 0.44, 0.18, 0.0, 0.0, 0.24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samri\\anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "bleu4=[]\n",
    "for i in range(len(auth_1)):\n",
    "    bleu4.append(round(sentence_bleu([refs[i]], preds[i]),2))\n",
    "print(bleu4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b0d3841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62, 0.72, 0.61, 0.71, 0.69, 0.56, 0.61, 0.63, 0.31, 0.24, 0.5, 0.5, 0.39, 0.13, 0.34, 0.29, 0.26, 0.7, 0.49, 0.15, 0.04, 0.32, 0.54, 0.34, 0.32, 0.43, 0.27, 0.71, 0.47, 0.61, 0.49, 0.52, 0.55, 0.26, 0.37, 0.92, 0.08, 0.42, 0.57, 0.52, 0.0, 0.52, 0.36, 0.42, 0.79, 0.13, 0.1, 0.13, 0.17, 0.27, 0.21, 0.39, 0.18, 0.29, 0.26, 0.38, 0.31, 0.11, 0.31, 0.13, 0.35, 0.32, 0.22, 0.1, 0.35, 0.13, 0.16, 0.44, 0.0, 0.46, 0.27, 0.25, 0.23, 0.44, 0.13, 0.49, 0.53, 0.28, 0.25, 0.3, 0.35, 0.26, 0.21, 0.16, 0.32, 0.24, 0.27, 0.17, 0.44, 0.18, 0.0, 0.0, 0.24]\n"
     ]
    }
   ],
   "source": [
    "norm_bleu4 = []\n",
    "\n",
    "max_b4=max(bleu4)\n",
    "min_b4=min(bleu4)\n",
    "\n",
    "for a in range(len(bleu4)):\n",
    "    norm_bleu4.append(round(((bleu4[a])/(max_b4)),2))\n",
    "print(norm_bleu4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19cccbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmans correlation coefficient: 0.705\n",
      "correlated (reject H0) p=0.000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# calculate spearman's correlation\n",
    "coef, p = spearmanr(norm_bleu4, avg_norm_score)\n",
    "print('Spearmans correlation coefficient: %.3f' % coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "else:\n",
    "\tprint('correlated (reject H0) p=%.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf37e62",
   "metadata": {},
   "source": [
    "# BLEUNorm with punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "601e6cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.57, 0.74, 0.63, 0.72, 0.7, 0.56, 0.78, 0.64, 0.35, 0.2, 0.5, 0.5, 0.42, 0.12, 0.38, 0.28, 0.22, 0.72, 0.51, 0.18, 0.05, 0.33, 0.54, 0.34, 0.35, 0.45, 0.27, 0.78, 0.48, 0.63, 0.48, 0.5, 0.57, 0.29, 0.39, 0.92, 0.11, 0.46, 0.61, 0.52, 0.1, 0.54, 0.39, 0.41, 0.81, 0.13, 0.13, 0.19, 0.21, 0.27, 0.25, 0.43, 0.19, 0.29, 0.28, 0.38, 0.24, 0.15, 0.33, 0.17, 0.33, 0.32, 0.25, 0.15, 0.39, 0.19, 0.19, 0.45, 0.03, 0.49, 0.28, 0.27, 0.26, 0.49, 0.15, 0.51, 0.54, 0.26, 0.23, 0.3, 0.35, 0.32, 0.26, 0.21, 0.32, 0.22, 0.28, 0.18, 0.52, 0.22, 0.08, 0.05, 0.26]\n"
     ]
    }
   ],
   "source": [
    "bleun_pr=[]\n",
    "for i in range(len(auth_1)):\n",
    "    bleun_pr.append(round(sentence_bleu([refs_n[i]], preds_n[i],smoothing_function=SmoothingFunction().method2),2))\n",
    "print(bleun_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f87a3823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.57, 0.74, 0.63, 0.72, 0.7, 0.56, 0.78, 0.64, 0.35, 0.2, 0.5, 0.5, 0.42, 0.12, 0.38, 0.28, 0.22, 0.72, 0.51, 0.18, 0.05, 0.33, 0.54, 0.34, 0.35, 0.45, 0.27, 0.78, 0.48, 0.63, 0.48, 0.5, 0.57, 0.29, 0.39, 0.92, 0.11, 0.46, 0.61, 0.52, 0.1, 0.54, 0.39, 0.41, 0.81, 0.13, 0.13, 0.19, 0.21, 0.27, 0.25, 0.43, 0.19, 0.29, 0.28, 0.38, 0.24, 0.15, 0.33, 0.17, 0.33, 0.32, 0.25, 0.15, 0.39, 0.19, 0.19, 0.45, 0.03, 0.49, 0.28, 0.27, 0.26, 0.49, 0.15, 0.51, 0.54, 0.26, 0.23, 0.3, 0.35, 0.32, 0.26, 0.21, 0.32, 0.22, 0.28, 0.18, 0.52, 0.22, 0.08, 0.05, 0.26]\n"
     ]
    }
   ],
   "source": [
    "norm_bleun_pr = []\n",
    "\n",
    "max_bn=max(bleun_pr)\n",
    "min_bn=min(bleun_pr)\n",
    "\n",
    "for a in range(len(bleun_pr)):\n",
    "    norm_bleun_pr.append(round(((bleun_pr[a])/(max_bn)),2))\n",
    "print(norm_bleun_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aca80fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmans correlation coefficient: 0.699\n",
      "correlated (reject H0) p=0.000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# calculate spearman's correlation\n",
    "coef, p = spearmanr(norm_bleun_pr, avg_norm_score)\n",
    "print('Spearmans correlation coefficient: %.3f' % coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "else:\n",
    "\tprint('correlated (reject H0) p=%.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16fe72f",
   "metadata": {},
   "source": [
    "# BLEUNorm without punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5111ea43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62, 0.74, 0.63, 0.72, 0.7, 0.56, 0.61, 0.64, 0.35, 0.24, 0.51, 0.51, 0.42, 0.16, 0.38, 0.32, 0.29, 0.71, 0.51, 0.18, 0.05, 0.32, 0.56, 0.34, 0.32, 0.45, 0.27, 0.73, 0.48, 0.61, 0.5, 0.53, 0.55, 0.29, 0.39, 0.92, 0.09, 0.44, 0.58, 0.53, 0.11, 0.53, 0.38, 0.43, 0.8, 0.13, 0.13, 0.18, 0.21, 0.27, 0.25, 0.39, 0.2, 0.31, 0.28, 0.39, 0.31, 0.14, 0.33, 0.17, 0.36, 0.32, 0.24, 0.14, 0.37, 0.18, 0.19, 0.45, 0.03, 0.47, 0.28, 0.27, 0.25, 0.45, 0.15, 0.5, 0.54, 0.29, 0.26, 0.31, 0.36, 0.28, 0.23, 0.18, 0.33, 0.25, 0.28, 0.18, 0.46, 0.2, 0.1, 0.05, 0.27]\n"
     ]
    }
   ],
   "source": [
    "bleun=[]\n",
    "for i in range(len(auth_1)):\n",
    "    bleun.append(round(sentence_bleu([refs[i]], preds[i],smoothing_function=SmoothingFunction().method2),2))\n",
    "print(bleun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fbf918f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62, 0.74, 0.63, 0.72, 0.7, 0.56, 0.61, 0.64, 0.35, 0.24, 0.51, 0.51, 0.42, 0.16, 0.38, 0.32, 0.29, 0.71, 0.51, 0.18, 0.05, 0.32, 0.56, 0.34, 0.32, 0.45, 0.27, 0.73, 0.48, 0.61, 0.5, 0.53, 0.55, 0.29, 0.39, 0.92, 0.09, 0.44, 0.58, 0.53, 0.11, 0.53, 0.38, 0.43, 0.8, 0.13, 0.13, 0.18, 0.21, 0.27, 0.25, 0.39, 0.2, 0.31, 0.28, 0.39, 0.31, 0.14, 0.33, 0.17, 0.36, 0.32, 0.24, 0.14, 0.37, 0.18, 0.19, 0.45, 0.03, 0.47, 0.28, 0.27, 0.25, 0.45, 0.15, 0.5, 0.54, 0.29, 0.26, 0.31, 0.36, 0.28, 0.23, 0.18, 0.33, 0.25, 0.28, 0.18, 0.46, 0.2, 0.1, 0.05, 0.27]\n"
     ]
    }
   ],
   "source": [
    "norm_bleun = []\n",
    "\n",
    "max_bn=max(bleun)\n",
    "min_bn=min(bleun)\n",
    "\n",
    "for a in range(len(bleun)):\n",
    "    norm_bleun.append(round(((bleun[a])/(max_bn)),2))\n",
    "print(norm_bleun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a24359f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmans correlation coefficient: 0.691\n",
      "correlated (reject H0) p=0.000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# calculate spearman's correlation\n",
    "coef, p = spearmanr(norm_bleun, avg_norm_score)\n",
    "print('Spearmans correlation coefficient: %.3f' % coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "else:\n",
    "\tprint('correlated (reject H0) p=%.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16604c6",
   "metadata": {},
   "source": [
    "# BLEUCC with punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa972fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.12, 1.12, 1.12, 1.12, 1.12, 1.12, 1.12, 0.64, 0.81, 0.71, 0.82, 0.79, 0.63, 0.79, 0.69, 0.39, 0.22, 0.61, 0.61, 0.47, 0.16, 0.41, 0.34, 0.26, 0.8, 0.58, 0.19, 0.05, 0.37, 0.62, 0.38, 0.39, 0.51, 0.3, 0.88, 0.57, 0.7, 0.56, 0.57, 0.63, 0.33, 0.46, 1.02, 0.12, 0.52, 0.67, 0.59, 0.11, 0.64, 0.45, 0.5, 0.9, 0.15, 0.19, 0.21, 0.26, 0.36, 0.29, 0.48, 0.22, 0.36, 0.36, 0.46, 0.27, 0.17, 0.38, 0.22, 0.41, 0.37, 0.31, 0.19, 0.45, 0.22, 0.24, 0.51, 0.04, 0.58, 0.33, 0.31, 0.32, 0.58, 0.18, 0.6, 0.61, 0.32, 0.3, 0.35, 0.44, 0.4, 0.3, 0.26, 0.37, 0.24, 0.3, 0.25, 0.58, 0.29, 0.12, 0.08, 0.32]\n"
     ]
    }
   ],
   "source": [
    "bleucc_pr=[]\n",
    "for i in range(len(auth_1)):\n",
    "    bleucc_pr.append(round(sentence_bleu([refs_n[i]], preds_n[i],smoothing_function=SmoothingFunction().method5),2))\n",
    "print(bleucc_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c161d887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.57, 0.72, 0.63, 0.73, 0.71, 0.56, 0.71, 0.62, 0.35, 0.2, 0.54, 0.54, 0.42, 0.14, 0.37, 0.3, 0.23, 0.71, 0.52, 0.17, 0.04, 0.33, 0.55, 0.34, 0.35, 0.46, 0.27, 0.79, 0.51, 0.62, 0.5, 0.51, 0.56, 0.29, 0.41, 0.91, 0.11, 0.46, 0.6, 0.53, 0.1, 0.57, 0.4, 0.45, 0.8, 0.13, 0.17, 0.19, 0.23, 0.32, 0.26, 0.43, 0.2, 0.32, 0.32, 0.41, 0.24, 0.15, 0.34, 0.2, 0.37, 0.33, 0.28, 0.17, 0.4, 0.2, 0.21, 0.46, 0.04, 0.52, 0.29, 0.28, 0.29, 0.52, 0.16, 0.54, 0.54, 0.29, 0.27, 0.31, 0.39, 0.36, 0.27, 0.23, 0.33, 0.21, 0.27, 0.22, 0.52, 0.26, 0.11, 0.07, 0.29]\n"
     ]
    }
   ],
   "source": [
    "norm_bleucc_pr = []\n",
    "\n",
    "max_bcc=max(bleucc_pr)\n",
    "min_bcc=min(bleucc_pr)\n",
    "\n",
    "for a in range(len(bleucc_pr)):\n",
    "    norm_bleucc_pr.append(round(((bleucc_pr[a])/(max_bcc)),2))\n",
    "print(norm_bleucc_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14143322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmans correlation coefficient: 0.693\n",
      "correlated (reject H0) p=0.000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# calculate spearman's correlation\n",
    "coef, p = spearmanr(norm_bleucc_pr, avg_norm_score)\n",
    "print('Spearmans correlation coefficient: %.3f' % coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "else:\n",
    "\tprint('correlated (reject H0) p=%.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353e5792",
   "metadata": {},
   "source": [
    "# BLEUCC without punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "099d30a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.12, 1.12, 1.12, 1.12, 1.12, 1.12, 1.12, 0.7, 0.81, 0.71, 0.82, 0.79, 0.63, 0.61, 0.69, 0.39, 0.26, 0.61, 0.61, 0.47, 0.21, 0.41, 0.38, 0.34, 0.79, 0.59, 0.19, 0.05, 0.35, 0.64, 0.38, 0.36, 0.52, 0.3, 0.81, 0.57, 0.68, 0.58, 0.61, 0.62, 0.33, 0.46, 1.03, 0.1, 0.51, 0.65, 0.61, 0.12, 0.62, 0.45, 0.51, 0.89, 0.15, 0.19, 0.21, 0.27, 0.37, 0.29, 0.44, 0.23, 0.38, 0.35, 0.47, 0.34, 0.16, 0.38, 0.22, 0.44, 0.37, 0.31, 0.18, 0.44, 0.2, 0.24, 0.52, 0.05, 0.56, 0.32, 0.32, 0.31, 0.54, 0.18, 0.59, 0.62, 0.36, 0.34, 0.36, 0.45, 0.35, 0.28, 0.23, 0.38, 0.27, 0.31, 0.25, 0.52, 0.27, 0.15, 0.09, 0.33]\n"
     ]
    }
   ],
   "source": [
    "bleucc=[]\n",
    "for i in range(len(auth_1)):\n",
    "    bleucc.append(round(sentence_bleu([refs[i]], preds[i],smoothing_function=SmoothingFunction().method5),2))\n",
    "print(bleucc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4f7ffdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62, 0.72, 0.63, 0.73, 0.71, 0.56, 0.54, 0.62, 0.35, 0.23, 0.54, 0.54, 0.42, 0.19, 0.37, 0.34, 0.3, 0.71, 0.53, 0.17, 0.04, 0.31, 0.57, 0.34, 0.32, 0.46, 0.27, 0.72, 0.51, 0.61, 0.52, 0.54, 0.55, 0.29, 0.41, 0.92, 0.09, 0.46, 0.58, 0.54, 0.11, 0.55, 0.4, 0.46, 0.79, 0.13, 0.17, 0.19, 0.24, 0.33, 0.26, 0.39, 0.21, 0.34, 0.31, 0.42, 0.3, 0.14, 0.34, 0.2, 0.39, 0.33, 0.28, 0.16, 0.39, 0.18, 0.21, 0.46, 0.04, 0.5, 0.29, 0.29, 0.28, 0.48, 0.16, 0.53, 0.55, 0.32, 0.3, 0.32, 0.4, 0.31, 0.25, 0.21, 0.34, 0.24, 0.28, 0.22, 0.46, 0.24, 0.13, 0.08, 0.29]\n"
     ]
    }
   ],
   "source": [
    "norm_bleucc = []\n",
    "\n",
    "max_bcc=max(bleucc)\n",
    "min_bcc=min(bleucc)\n",
    "\n",
    "for a in range(len(bleucc)):\n",
    "    norm_bleucc.append(round(((bleucc[a])/(max_bcc)),2))\n",
    "print(norm_bleucc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39552254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmans correlation coefficient: 0.681\n",
      "correlated (reject H0) p=0.000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# calculate spearman's correlation\n",
    "coef, p = spearmanr(norm_bleucc, avg_norm_score)\n",
    "print('Spearmans correlation coefficient: %.3f' % coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "else:\n",
    "\tprint('correlated (reject H0) p=%.3f' % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33e8f71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge in c:\\users\\samri\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\samri\\anaconda3\\lib\\site-packages (from rouge) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge\n",
    "from rouge import Rouge \n",
    "rouge = Rouge()\n",
    "\n",
    "def rouge1_scores(reference, hypothesis):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(hypothesis, reference)\n",
    "    dict=scores[0]\n",
    "    dict.values()\n",
    "    temp0 =list(dict.values())[0]\n",
    "    temp1= list(dict.values())[1]\n",
    "    temp2= list(dict.values())[2]\n",
    "    ROGUE_1 = temp0['f']\n",
    "    #ROGUE_2 = temp1['f']\n",
    "    #ROGUE_L = temp2['f']\n",
    "    return ROGUE_1\n",
    "\n",
    "def rouge2_scores(reference, hypothesis):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(hypothesis, reference)\n",
    "    dict=scores[0]\n",
    "    dict.values()\n",
    "    temp0 =list(dict.values())[0]\n",
    "    temp1= list(dict.values())[1]\n",
    "    temp2= list(dict.values())[2]\n",
    "    #ROGUE_1 = temp0['f']\n",
    "    ROGUE_2 = temp1['f']\n",
    "    #ROGUE_L = temp2['f']\n",
    "    return ROGUE_2\n",
    "\n",
    "def rougeL_scores(reference, hypothesis):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(hypothesis, reference)\n",
    "    dict=scores[0]\n",
    "    dict.values()\n",
    "    temp0 =list(dict.values())[0]\n",
    "    temp1= list(dict.values())[1]\n",
    "    temp2= list(dict.values())[2]\n",
    "    #ROGUE_1 = temp0['f']\n",
    "    #ROGUE_2 = temp1['f']\n",
    "    ROGUE_L = temp2['f']\n",
    "    return ROGUE_L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a67dae2",
   "metadata": {},
   "source": [
    "# ROUGE-1 with punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a12ed363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.29, 0.5, 0.33, 0.67, 0.75, 0.6, 1.0, 0.8, 0.0, 0.5, 0.8, 0.8, 0.33, 0.5, 0.25, 0.5, 0.29, 0.67, 0.75, 0.29, 0.33, 0.8, 0.6, 0.33, 0.55, 0.0, 0.67, 0.8, 0.2, 0.71, 0.25, 0.44, 0.4, 0.25, 0.57, 0.86, 0.33, 0.29, 0.5, 0.25, 0.0, 0.44, 0.4, 0.25, 0.71, 0.22, 0.25, 0.33, 0.0, 0.57, 0.25, 0.5, 0.18, 0.18, 0.4, 0.12, 0.31, 0.44, 0.33, 0.18, 0.22, 0.37, 0.25, 0.29, 0.29, 0.33, 0.22, 0.2, 0.0, 0.0, 0.27, 0.31, 0.5, 0.44, 0.36, 0.4, 0.43, 0.12, 0.15, 0.13, 0.15, 0.35, 0.36, 0.0, 0.31, 0.33, 0.2, 0.36, 0.67, 0.33, 0.0, 0.0, 0.25]\n"
     ]
    }
   ],
   "source": [
    "rouge1_pr=[]\n",
    "for i in range(len(auth_1)):\n",
    "    rouge1_pr.append(round(rouge1_scores(preds_n[i],refs_n[i]),2))\n",
    "print(rouge1_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1eb3986c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.29, 0.5, 0.33, 0.67, 0.75, 0.6, 1.0, 0.8, 0.0, 0.5, 0.8, 0.8, 0.33, 0.5, 0.25, 0.5, 0.29, 0.67, 0.75, 0.29, 0.33, 0.8, 0.6, 0.33, 0.55, 0.0, 0.67, 0.8, 0.2, 0.71, 0.25, 0.44, 0.4, 0.25, 0.57, 0.86, 0.33, 0.29, 0.5, 0.25, 0.0, 0.44, 0.4, 0.25, 0.71, 0.22, 0.25, 0.33, 0.0, 0.57, 0.25, 0.5, 0.18, 0.18, 0.4, 0.12, 0.31, 0.44, 0.33, 0.18, 0.22, 0.37, 0.25, 0.29, 0.29, 0.33, 0.22, 0.2, 0.0, 0.0, 0.27, 0.31, 0.5, 0.44, 0.36, 0.4, 0.43, 0.12, 0.15, 0.13, 0.15, 0.35, 0.36, 0.0, 0.31, 0.33, 0.2, 0.36, 0.67, 0.33, 0.0, 0.0, 0.25]\n"
     ]
    }
   ],
   "source": [
    "norm_r1_pr = []\n",
    "\n",
    "max_r1=max(rouge1_pr)\n",
    "min_r1=min(rouge1_pr)\n",
    "\n",
    "for a in range(len(rouge1_pr)):\n",
    "    norm_r1_pr.append(round(((rouge1_pr[a])/(max_r1)),2))\n",
    "print(norm_r1_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8fff0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmans correlation coefficient: 0.781\n",
      "correlated (reject H0) p=0.000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# calculate spearman's correlation\n",
    "coef, p = spearmanr(norm_r1_pr, avg_norm_score)\n",
    "print('Spearmans correlation coefficient: %.3f' % coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "else:\n",
    "\tprint('correlated (reject H0) p=%.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60da9b91",
   "metadata": {},
   "source": [
    "# ROUGE-1 without punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c165f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge1=[]\n",
    "for i in range(len(auth_1)):\n",
    "    rouge1.append(round(rouge1_scores(preds[i],refs[i]),2))\n",
    "print(rouge1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749d989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_r1 = []\n",
    "\n",
    "max_r1=max(rouge1)\n",
    "min_r1=min(rouge1)\n",
    "\n",
    "for a in range(len(rouge1)):\n",
    "    norm_r1.append(round(((rouge1[a])/(max_r1)),2))\n",
    "print(norm_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa32069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# calculate spearman's correlation\n",
    "coef, p = spearmanr(norm_r1, avg_norm_score)\n",
    "print('Spearmans correlation coefficient: %.3f' % coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "else:\n",
    "\tprint('correlated (reject H0) p=%.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdda9af",
   "metadata": {},
   "source": [
    "# ROUGE-2 with punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc8729c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.67, 0.5, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0, 0.0, 0.33, 0.0, 0.0, 0.67, 0.0, 0.0, 0.5, 0.25, 0.0, 0.44, 0.0, 0.29, 0.67, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.4, 0.67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.36, 0.0, 0.0, 0.15, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15, 0.18, 0.0, 0.35, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "rouge2_pr=[]\n",
    "for i in range(len(auth_1)):\n",
    "    rouge2_pr.append(round(rouge2_scores(preds_n[i],refs_n[i]),2))\n",
    "print(rouge2_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b66ee79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.67, 0.5, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0, 0.0, 0.33, 0.0, 0.0, 0.67, 0.0, 0.0, 0.5, 0.25, 0.0, 0.44, 0.0, 0.29, 0.67, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.4, 0.67, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.36, 0.0, 0.0, 0.15, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15, 0.18, 0.0, 0.35, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "norm_r2_pr = []\n",
    "\n",
    "max_r2=max(rouge2_pr)\n",
    "min_r2=min(rouge2_pr)\n",
    "\n",
    "for a in range(len(rouge2_pr)):\n",
    "    norm_r2_pr.append(round(((rouge2_pr[a])/(max_r2)),2))\n",
    "print(norm_r2_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ece9d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmans correlation coefficient: 0.485\n",
      "correlated (reject H0) p=0.000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# calculate spearman's correlation\n",
    "coef, p = spearmanr(norm_r2_pr, avg_norm_score)\n",
    "print('Spearmans correlation coefficient: %.3f' % coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "else:\n",
    "\tprint('correlated (reject H0) p=%.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e24d1d5",
   "metadata": {},
   "source": [
    "# ROUGE-2 without punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8d8ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge2=[]\n",
    "for i in range(len(auth_1)):\n",
    "    rouge2.append(round(rouge2_scores(preds[i],refs[i]),2))\n",
    "print(rouge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a934f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_r2 = []\n",
    "\n",
    "max_r2=max(rouge2)\n",
    "min_r2=min(rouge2)\n",
    "\n",
    "for a in range(len(rouge2)):\n",
    "    norm_r2.append(round(((rouge2[a])/(max_r2)),2))\n",
    "print(norm_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dfd179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# calculate spearman's correlation\n",
    "coef, p = spearmanr(norm_r2, avg_norm_score)\n",
    "print('Spearmans correlation coefficient: %.3f' % coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "else:\n",
    "\tprint('correlated (reject H0) p=%.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e95e42",
   "metadata": {},
   "source": [
    "# ROUGE-L with punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20658507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.29, 0.5, 0.33, 0.67, 0.75, 0.6, 1.0, 0.8, 0.0, 0.5, 0.8, 0.8, 0.33, 0.5, 0.25, 0.5, 0.29, 0.67, 0.75, 0.29, 0.33, 0.8, 0.6, 0.33, 0.55, 0.0, 0.67, 0.8, 0.2, 0.71, 0.25, 0.44, 0.4, 0.25, 0.57, 0.86, 0.33, 0.29, 0.5, 0.25, 0.0, 0.44, 0.4, 0.25, 0.71, 0.22, 0.25, 0.33, 0.0, 0.57, 0.25, 0.5, 0.18, 0.18, 0.4, 0.12, 0.31, 0.44, 0.33, 0.18, 0.22, 0.37, 0.25, 0.29, 0.29, 0.33, 0.22, 0.2, 0.0, 0.0, 0.27, 0.31, 0.5, 0.44, 0.36, 0.4, 0.43, 0.12, 0.15, 0.13, 0.15, 0.35, 0.36, 0.0, 0.31, 0.33, 0.2, 0.36, 0.67, 0.33, 0.0, 0.0, 0.25]\n"
     ]
    }
   ],
   "source": [
    "rougel_pr=[]\n",
    "for i in range(len(auth_1)):\n",
    "    rougel_pr.append(round(rougeL_scores(preds_n[i],refs_n[i]),2))\n",
    "print(rougel_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50b17e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.29, 0.5, 0.33, 0.67, 0.75, 0.6, 1.0, 0.8, 0.0, 0.5, 0.8, 0.8, 0.33, 0.5, 0.25, 0.5, 0.29, 0.67, 0.75, 0.29, 0.33, 0.8, 0.6, 0.33, 0.55, 0.0, 0.67, 0.8, 0.2, 0.71, 0.25, 0.44, 0.4, 0.25, 0.57, 0.86, 0.33, 0.29, 0.5, 0.25, 0.0, 0.44, 0.4, 0.25, 0.71, 0.22, 0.25, 0.33, 0.0, 0.57, 0.25, 0.5, 0.18, 0.18, 0.4, 0.12, 0.31, 0.44, 0.33, 0.18, 0.22, 0.37, 0.25, 0.29, 0.29, 0.33, 0.22, 0.2, 0.0, 0.0, 0.27, 0.31, 0.5, 0.44, 0.36, 0.4, 0.43, 0.12, 0.15, 0.13, 0.15, 0.35, 0.36, 0.0, 0.31, 0.33, 0.2, 0.36, 0.67, 0.33, 0.0, 0.0, 0.25]\n"
     ]
    }
   ],
   "source": [
    "norm_rl_pr = []\n",
    "\n",
    "max_rl=max(rougel_pr)\n",
    "min_rl=min(rougel_pr)\n",
    "\n",
    "for a in range(len(rougel_pr)):\n",
    "    norm_rl_pr.append(round(((rougel_pr[a])/(max_rl)),2))\n",
    "print(norm_rl_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "667c92ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmans correlation coefficient: 0.781\n",
      "correlated (reject H0) p=0.000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# calculate spearman's correlation\n",
    "coef, p = spearmanr(norm_rl_pr, avg_norm_score)\n",
    "print('Spearmans correlation coefficient: %.3f' % coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "else:\n",
    "\tprint('correlated (reject H0) p=%.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687748b7",
   "metadata": {},
   "source": [
    "# ROUGE-L without punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd559a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rougel=[]\n",
    "for i in range(len(auth_1)):\n",
    "    rougel.append(round(rougeL_scores(preds_n[i],refs_n[i]),2))\n",
    "print(rougel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4e28c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_rl = []\n",
    "\n",
    "max_rl=max(rougel)\n",
    "min_rl=min(rougel)\n",
    "\n",
    "for a in range(len(rougel)):\n",
    "    norm_rl.append(round(((rougel[a])/(max_rl)),2))\n",
    "print(norm_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ec93f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# calculate spearman's correlation\n",
    "coef, p = spearmanr(norm_rl, avg_norm_score)\n",
    "print('Spearmans correlation coefficient: %.3f' % coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "else:\n",
    "\tprint('correlated (reject H0) p=%.3f' % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "308137da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9b10d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wer_score(hyp, ref, print_matrix=False):\n",
    "    N = len(hyp)\n",
    "    M = len(ref)\n",
    "    L = np.zeros((N,M))\n",
    "    for i in range(0, N):\n",
    "        for j in range(0, M):\n",
    "            if min(i,j) == 0:\n",
    "                L[i,j] = max(i,j)\n",
    "            else:\n",
    "                deletion = L[i-1,j] + 1\n",
    "                insertion = L[i,j-1] + 1\n",
    "                sub = 1 if hyp[i] != ref[j] else 0\n",
    "                substitution = L[i-1,j-1] + sub\n",
    "                L[i,j] = min(deletion, min(insertion, substitution))\n",
    "                #print(\"{} - {}: del {} ins {} sub {} s {}\".format(hyp[i], ref[j], deletion, insertion, substitution, sub))\n",
    "    if print_matrix:\n",
    "        print(\"WER matrix ({}x{}): \".format(N, M))\n",
    "        print(L)\n",
    "    return int(L[N-1, M-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9633b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ter(hyp, ref):\n",
    "    ref = str(ref).split()\n",
    "    r=len(ref)\n",
    "    hyp=str(hyp).split()\n",
    "    wer=wer_score(hyp, ref, print_matrix = False)\n",
    "    return wer/r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca97302",
   "metadata": {},
   "source": [
    "# TER without punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58a481b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.33, 0.33, 0.25, 0.5, 0.5, 0.33, 0.67, 0.5, 0.67, 0.67, 0.67, 0.25, 0.75, 0.5, 0.5, 0.75, 0.75, 0.75, 0.75, 0.43, 0.5, 0.5, 0.67, 1.0, 0.5, 0.5, 2.0, 0.36, 0.6, 0.67, 0.5, 0.8, 1.0, 0.1, 0.83, 1.0, 0.55, 0.8, 0.6, 1.25, 0.56, 0.67, 0.33, 0.67, 1.33, 1.5, 0.6, 1.86, 1.0, 0.56, 0.86, 0.89, 1.0, 0.75, 0.53, 0.71, 0.71, 0.83, 0.79, 0.71, 1.25, 1.67, 1.25, 1.33, 1.67, 0.83, 0.86, 1.67, 0.69, 0.86, 2.5, 1.0, 0.62, 1.0, 0.86, 1.0, 1.0, 0.77, 1.0, 0.69, 0.88, 0.89, 0.86, 0.7, 0.75, 1.5, 1.75, 3.0, 1.0, 2.5, 1.25]\n"
     ]
    }
   ],
   "source": [
    "ter_=[]\n",
    "for i in range(len(auth_1)):\n",
    "    ter_.append(round(ter(preds[i],refs[i]),2))\n",
    "print(ter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9966aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.11, 0.11, 0.08, 0.17, 0.17, 0.11, 0.22, 0.17, 0.22, 0.22, 0.22, 0.08, 0.25, 0.17, 0.17, 0.25, 0.25, 0.25, 0.25, 0.14, 0.17, 0.17, 0.22, 0.33, 0.17, 0.17, 0.67, 0.12, 0.2, 0.22, 0.17, 0.27, 0.33, 0.03, 0.28, 0.33, 0.18, 0.27, 0.2, 0.42, 0.19, 0.22, 0.11, 0.22, 0.44, 0.5, 0.2, 0.62, 0.33, 0.19, 0.29, 0.3, 0.33, 0.25, 0.18, 0.24, 0.24, 0.28, 0.26, 0.24, 0.42, 0.56, 0.42, 0.44, 0.56, 0.28, 0.29, 0.56, 0.23, 0.29, 0.83, 0.33, 0.21, 0.33, 0.29, 0.33, 0.33, 0.26, 0.33, 0.23, 0.29, 0.3, 0.29, 0.23, 0.25, 0.5, 0.58, 1.0, 0.33, 0.83, 0.42]\n"
     ]
    }
   ],
   "source": [
    "norm_t = []\n",
    "\n",
    "max_t=max(ter_)\n",
    "min_t=min(ter_)\n",
    "\n",
    "for a in range(len(ter_)):\n",
    "    norm_t.append(round(((ter_[a])/(max_t)),2))\n",
    "print(norm_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3405ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.89, 0.89, 0.92, 0.83, 0.83, 0.89, 0.78, 0.83, 0.78, 0.78, 0.78, 0.92, 0.75, 0.83, 0.83, 0.75, 0.75, 0.75, 0.75, 0.86, 0.83, 0.83, 0.78, 0.67, 0.83, 0.83, 0.33, 0.88, 0.8, 0.78, 0.83, 0.73, 0.67, 0.97, 0.72, 0.67, 0.82, 0.73, 0.8, 0.58, 0.81, 0.78, 0.89, 0.78, 0.56, 0.5, 0.8, 0.38, 0.67, 0.81, 0.71, 0.7, 0.67, 0.75, 0.82, 0.76, 0.76, 0.72, 0.74, 0.76, 0.58, 0.44, 0.58, 0.56, 0.44, 0.72, 0.71, 0.44, 0.77, 0.71, 0.17, 0.67, 0.79, 0.67, 0.71, 0.67, 0.67, 0.74, 0.67, 0.77, 0.71, 0.7, 0.71, 0.77, 0.75, 0.5, 0.42, 0.0, 0.67, 0.17, 0.58]\n"
     ]
    }
   ],
   "source": [
    "t_sim = []\n",
    "for i in range(len(norm_t)):\n",
    "    t_sim.append(round((1-norm_t[i]),2))\n",
    "print(t_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c3b36ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmans correlation coefficient: 0.568\n",
      "correlated (reject H0) p=0.000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# calculate spearman's correlation\n",
    "coef, p = spearmanr(t_sim, avg_norm_score)\n",
    "print('Spearmans correlation coefficient: %.3f' % coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "else:\n",
    "\tprint('correlated (reject H0) p=%.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb34899",
   "metadata": {},
   "source": [
    "# TER with punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0906ac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ter_pr=[]\n",
    "for i in range(len(auth_1)):\n",
    "    ter_pr.append(round(ter(preds_n[i],refs_n[i]),2))\n",
    "print(ter_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8ed928",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_t_pr = []\n",
    "\n",
    "max_t=max(ter_pr)\n",
    "min_t=min(ter_pr)\n",
    "\n",
    "for a in range(len(ter_pr)):\n",
    "    norm_t_pr.append(round(((ter_pr[a])/(max_t)),2))\n",
    "print(norm_t_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06394a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_sim_pr = []\n",
    "for i in range(len(norm_t_pr)):\n",
    "    t_sim_pr.append(round((1-norm_t_pr[i]),2))\n",
    "print(t_sim_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1034818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# calculate spearman's correlation\n",
    "coef, p = spearmanr(t_sim_pr, avg_norm_score)\n",
    "print('Spearmans correlation coefficient: %.3f' % coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "else:\n",
    "\tprint('correlated (reject H0) p=%.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15f0178",
   "metadata": {},
   "source": [
    "# METEOR without punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35289b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.meteor_score import meteor_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de12cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor=[]\n",
    "for i in range(len(auth_1)):\n",
    "    meteor.append(round(meteor_score([refs[i]], preds[i]),2))\n",
    "print(meteor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7fd6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_m = []\n",
    "\n",
    "max_m=max(meteor)\n",
    "min_m=min(meteor)\n",
    "\n",
    "for a in range(len(meteor)):\n",
    "    norm_m.append(round(((meteor[a])/(max_m)),2))\n",
    "print(norm_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf90b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# calculate spearman's correlation\n",
    "coef, p = spearmanr(norm_m, avg_norm_score)\n",
    "print('Spearmans correlation coefficient: %.3f' % coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "else:\n",
    "\tprint('correlated (reject H0) p=%.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ac5c0c",
   "metadata": {},
   "source": [
    "# METEOR with punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bcb847",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor_pr=[]\n",
    "for i in range(len(auth_1)):\n",
    "    meteor_pr.append(round(meteor_score([refs_n[i]], preds_n[i]),2))\n",
    "print(meteor_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4e3410",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_m_pr = []\n",
    "\n",
    "max_m=max(meteor_pr)\n",
    "min_m=min(meteor_pr)\n",
    "\n",
    "for a in range(len(meteor_pr)):\n",
    "    norm_m_pr.append(round(((meteor_pr[a])/(max_m)),2))\n",
    "print(norm_m_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cac266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# calculate spearman's correlation\n",
    "coef, p = spearmanr(norm_m_pr, avg_norm_score)\n",
    "print('Spearmans correlation coefficient: %.3f' % coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "else:\n",
    "\tprint('correlated (reject H0) p=%.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fd401a",
   "metadata": {},
   "source": [
    "# METEOR-NEXT without punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6d9483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from itertools import chain, product\n",
    "\n",
    "\n",
    "def _generate_enums(hypothesis, reference, preprocess=str.lower):\n",
    "    \"\"\"\n",
    "    Takes in string inputs for hypothesis and reference and returns\n",
    "    enumerated word lists for each of them\n",
    "\n",
    "    :param hypothesis: hypothesis string\n",
    "    :type hypothesis: str\n",
    "    :param reference: reference string\n",
    "    :type reference: str\n",
    "    :preprocess: preprocessing method (default str.lower)\n",
    "    :type preprocess: method\n",
    "    :return: enumerated words list\n",
    "    :rtype: list of 2D tuples, list of 2D tuples\n",
    "    \"\"\"\n",
    "    hypothesis_list = list(enumerate(preprocess(hypothesis).split()))\n",
    "    reference_list = list(enumerate(preprocess(reference).split()))\n",
    "    return hypothesis_list, reference_list\n",
    "\n",
    "\n",
    "def exact_match(hypothesis, reference):\n",
    "    \"\"\"\n",
    "    matches exact words in hypothesis and reference\n",
    "    and returns a word mapping based on the enumerated\n",
    "    word id between hypothesis and reference\n",
    "\n",
    "    :param hypothesis: hypothesis string\n",
    "    :type hypothesis: str\n",
    "    :param reference: reference string\n",
    "    :type reference: str\n",
    "    :return: enumerated matched tuples, enumerated unmatched hypothesis tuples,\n",
    "             enumerated unmatched reference tuples\n",
    "    :rtype: list of 2D tuples, list of 2D tuples,  list of 2D tuples\n",
    "    \"\"\"\n",
    "    hypothesis_list, reference_list = _generate_enums(hypothesis, reference)\n",
    "    return _match_enums(hypothesis_list, reference_list)\n",
    "\n",
    "\n",
    "\n",
    "def _match_enums(enum_hypothesis_list, enum_reference_list):\n",
    "    \"\"\"\n",
    "    matches exact words in hypothesis and reference and returns\n",
    "    a word mapping between enum_hypothesis_list and enum_reference_list\n",
    "    based on the enumerated word id.\n",
    "\n",
    "    :param enum_hypothesis_list: enumerated hypothesis list\n",
    "    :type enum_hypothesis_list: list of tuples\n",
    "    :param enum_reference_list: enumerated reference list\n",
    "    :type enum_reference_list: list of 2D tuples\n",
    "    :return: enumerated matched tuples, enumerated unmatched hypothesis tuples,\n",
    "             enumerated unmatched reference tuples\n",
    "    :rtype: list of 2D tuples, list of 2D tuples,  list of 2D tuples\n",
    "    \"\"\"\n",
    "    word_match = []\n",
    "    for i in range(len(enum_hypothesis_list))[::-1]:\n",
    "        for j in range(len(enum_reference_list))[::-1]:\n",
    "            if enum_hypothesis_list[i][1] == enum_reference_list[j][1]:\n",
    "                word_match.append(\n",
    "                    (enum_hypothesis_list[i][0], enum_reference_list[j][0])\n",
    "                )\n",
    "                (enum_hypothesis_list.pop(i)[1], enum_reference_list.pop(j)[1])\n",
    "                break\n",
    "    return word_match, enum_hypothesis_list, enum_reference_list\n",
    "\n",
    "\n",
    "def _enum_stem_match(\n",
    "    enum_hypothesis_list, enum_reference_list, stemmer=PorterStemmer()\n",
    "):\n",
    "    \"\"\"\n",
    "    Stems each word and matches them in hypothesis and reference\n",
    "    and returns a word mapping between enum_hypothesis_list and\n",
    "    enum_reference_list based on the enumerated word id. The function also\n",
    "    returns a enumerated list of unmatched words for hypothesis and reference.\n",
    "\n",
    "    :param enum_hypothesis_list:\n",
    "    :type enum_hypothesis_list:\n",
    "    :param enum_reference_list:\n",
    "    :type enum_reference_list:\n",
    "    :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer())\n",
    "    :type stemmer: nltk.stem.api.StemmerI or any class that implements a stem method\n",
    "    :return: enumerated matched tuples, enumerated unmatched hypothesis tuples,\n",
    "             enumerated unmatched reference tuples\n",
    "    :rtype: list of 2D tuples, list of 2D tuples,  list of 2D tuples\n",
    "    \"\"\"\n",
    "    stemmed_enum_list1 = [\n",
    "        (word_pair[0], stemmer.stem(word_pair[1])) for word_pair in enum_hypothesis_list\n",
    "    ]\n",
    "\n",
    "    stemmed_enum_list2 = [\n",
    "        (word_pair[0], stemmer.stem(word_pair[1])) for word_pair in enum_reference_list\n",
    "    ]\n",
    "\n",
    "    word_match, enum_unmat_hypo_list, enum_unmat_ref_list = _match_enums(\n",
    "        stemmed_enum_list1, stemmed_enum_list2\n",
    "    )\n",
    "\n",
    "    enum_unmat_hypo_list = (\n",
    "        list(zip(*enum_unmat_hypo_list)) if len(enum_unmat_hypo_list) > 0 else []\n",
    "    )\n",
    "\n",
    "    enum_unmat_ref_list = (\n",
    "        list(zip(*enum_unmat_ref_list)) if len(enum_unmat_ref_list) > 0 else []\n",
    "    )\n",
    "\n",
    "    enum_hypothesis_list = list(\n",
    "        filter(lambda x: x[0] not in enum_unmat_hypo_list, enum_hypothesis_list)\n",
    "    )\n",
    "\n",
    "    enum_reference_list = list(\n",
    "        filter(lambda x: x[0] not in enum_unmat_ref_list, enum_reference_list)\n",
    "    )\n",
    "\n",
    "    return word_match, enum_hypothesis_list, enum_reference_list\n",
    "\n",
    "\n",
    "def stem_match(hypothesis, reference, stemmer=PorterStemmer()):\n",
    "    \"\"\"\n",
    "    Stems each word and matches them in hypothesis and reference\n",
    "    and returns a word mapping between hypothesis and reference\n",
    "\n",
    "    :param hypothesis:\n",
    "    :type hypothesis:\n",
    "    :param reference:\n",
    "    :type reference:\n",
    "    :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer())\n",
    "    :type stemmer: nltk.stem.api.StemmerI or any class that\n",
    "                   implements a stem method\n",
    "    :return: enumerated matched tuples, enumerated unmatched hypothesis tuples,\n",
    "             enumerated unmatched reference tuples\n",
    "    :rtype: list of 2D tuples, list of 2D tuples,  list of 2D tuples\n",
    "    \"\"\"\n",
    "    enum_hypothesis_list, enum_reference_list = _generate_enums(hypothesis, reference)\n",
    "    return _enum_stem_match(enum_hypothesis_list, enum_reference_list, stemmer=stemmer)\n",
    "\n",
    "\n",
    "\n",
    "def _enum_wordnetsyn_match(enum_hypothesis_list, enum_reference_list, wordnet=wordnet):\n",
    "    \"\"\"\n",
    "    Matches each word in reference to a word in hypothesis\n",
    "    if any synonym of a hypothesis word is the exact match\n",
    "    to the reference word.\n",
    "\n",
    "    :param enum_hypothesis_list: enumerated hypothesis list\n",
    "    :param enum_reference_list: enumerated reference list\n",
    "    :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet)\n",
    "    :type wordnet: WordNetCorpusReader\n",
    "    :return: list of matched tuples, unmatched hypothesis list, unmatched reference list\n",
    "    :rtype:  list of tuples, list of tuples, list of tuples\n",
    "\n",
    "    \"\"\"\n",
    "    word_match = []\n",
    "    for i in range(len(enum_hypothesis_list))[::-1]:\n",
    "        hypothesis_syns = set(\n",
    "            chain.from_iterable(\n",
    "                (\n",
    "                    lemma.name()\n",
    "                    for lemma in synset.lemmas()\n",
    "                    if lemma.name().find(\"_\") < 0\n",
    "                )\n",
    "                for synset in wordnet.synsets(enum_hypothesis_list[i][1])\n",
    "            )\n",
    "        ).union({enum_hypothesis_list[i][1]})\n",
    "        for j in range(len(enum_reference_list))[::-1]:\n",
    "            if enum_reference_list[j][1] in hypothesis_syns:\n",
    "                word_match.append(\n",
    "                    (enum_hypothesis_list[i][0], enum_reference_list[j][0])\n",
    "                )\n",
    "                enum_hypothesis_list.pop(i), enum_reference_list.pop(j)\n",
    "                break\n",
    "    return word_match, enum_hypothesis_list, enum_reference_list\n",
    "\n",
    "\n",
    "def wordnetsyn_match(hypothesis, reference, wordnet=wordnet):\n",
    "    \"\"\"\n",
    "    Matches each word in reference to a word in hypothesis if any synonym\n",
    "    of a hypothesis word is the exact match to the reference word.\n",
    "\n",
    "    :param hypothesis: hypothesis string\n",
    "    :param reference: reference string\n",
    "    :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet)\n",
    "    :type wordnet: WordNetCorpusReader\n",
    "    :return: list of mapped tuples\n",
    "    :rtype: list of tuples\n",
    "    \"\"\"\n",
    "    enum_hypothesis_list, enum_reference_list = _generate_enums(hypothesis, reference)\n",
    "    return _enum_wordnetsyn_match(\n",
    "        enum_hypothesis_list, enum_reference_list, wordnet=wordnet\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def _enum_allign_words(\n",
    "    enum_hypothesis_list, enum_reference_list, stemmer=PorterStemmer(), wordnet=wordnet\n",
    "):\n",
    "    \"\"\"\n",
    "    Aligns/matches words in the hypothesis to reference by sequentially\n",
    "    applying exact match, stemmed match and wordnet based synonym match.\n",
    "    in case there are multiple matches the match which has the least number\n",
    "    of crossing is chosen. Takes enumerated list as input instead of\n",
    "    string input\n",
    "\n",
    "    :param enum_hypothesis_list: enumerated hypothesis list\n",
    "    :param enum_reference_list: enumerated reference list\n",
    "    :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer())\n",
    "    :type stemmer: nltk.stem.api.StemmerI or any class that implements a stem method\n",
    "    :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet)\n",
    "    :type wordnet: WordNetCorpusReader\n",
    "    :return: sorted list of matched tuples, unmatched hypothesis list,\n",
    "             unmatched reference list\n",
    "    :rtype: list of tuples, list of tuples, list of tuples\n",
    "    \"\"\"\n",
    "    exact_matches, enum_hypothesis_list, enum_reference_list = _match_enums(\n",
    "        enum_hypothesis_list, enum_reference_list\n",
    "    )\n",
    "\n",
    "    stem_matches, enum_hypothesis_list, enum_reference_list = _enum_stem_match(\n",
    "        enum_hypothesis_list, enum_reference_list, stemmer=stemmer\n",
    "    )\n",
    "\n",
    "    wns_matches, enum_hypothesis_list, enum_reference_list = _enum_wordnetsyn_match(\n",
    "        enum_hypothesis_list, enum_reference_list, wordnet=wordnet\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        sorted(\n",
    "            exact_matches + stem_matches + wns_matches, key=lambda wordpair: wordpair[0]\n",
    "        ),\n",
    "        enum_hypothesis_list,\n",
    "        enum_reference_list,\n",
    "    )\n",
    "\n",
    "\n",
    "def allign_words(hypothesis, reference, stemmer=PorterStemmer(), wordnet=wordnet):\n",
    "    \"\"\"\n",
    "    Aligns/matches words in the hypothesis to reference by sequentially\n",
    "    applying exact match, stemmed match and wordnet based synonym match.\n",
    "    In case there are multiple matches the match which has the least number\n",
    "    of crossing is chosen.\n",
    "\n",
    "    :param hypothesis: hypothesis string\n",
    "    :param reference: reference string\n",
    "    :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer())\n",
    "    :type stemmer: nltk.stem.api.StemmerI or any class that implements a stem method\n",
    "    :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet)\n",
    "    :type wordnet: WordNetCorpusReader\n",
    "    :return: sorted list of matched tuples, unmatched hypothesis list, unmatched reference list\n",
    "    :rtype: list of tuples, list of tuples, list of tuples\n",
    "    \"\"\"\n",
    "    enum_hypothesis_list, enum_reference_list = _generate_enums(hypothesis, reference)\n",
    "    return _enum_allign_words(\n",
    "        enum_hypothesis_list, enum_reference_list, stemmer=stemmer, wordnet=wordnet\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def _count_chunks(matches):\n",
    "    \"\"\"\n",
    "    Counts the fewest possible number of chunks such that matched unigrams\n",
    "    of each chunk are adjacent to each other. This is used to caluclate the\n",
    "    fragmentation part of the metric.\n",
    "\n",
    "    :param matches: list containing a mapping of matched words (output of allign_words)\n",
    "    :return: Number of chunks a sentence is divided into post allignment\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    chunks = 1\n",
    "    while i < len(matches) - 1:\n",
    "        if (matches[i + 1][0] == matches[i][0] + 1) and (\n",
    "            matches[i + 1][1] == matches[i][1] + 1\n",
    "        ):\n",
    "            i += 1\n",
    "            continue\n",
    "        i += 1\n",
    "        chunks += 1\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def single_meteor_score(\n",
    "    reference,\n",
    "    hypothesis,\n",
    "    preprocess=str.lower,\n",
    "    stemmer=PorterStemmer(),\n",
    "    wordnet=wordnet,\n",
    "    alpha=0.85,\n",
    "    beta=2.35,\n",
    "    gamma=0.45,\n",
    "    w_1=1,\n",
    "    w_2=0.8,\n",
    "    w_3=0.6\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates METEOR score for single hypothesis and reference as per\n",
    "    \"Meteor: An Automatic Metric for MT Evaluation with HighLevels of\n",
    "    Correlation with Human Judgments\" by Alon Lavie and Abhaya Agarwal,\n",
    "    in Proceedings of ACL.\n",
    "    http://www.cs.cmu.edu/~alavie/METEOR/pdf/Lavie-Agarwal-2007-METEOR.pdf\n",
    "\n",
    "\n",
    "    >>> hypothesis1 = 'It is a guide to action which ensures that the military always obeys the commands of the party'\n",
    "\n",
    "    >>> reference1 = 'It is a guide to action that ensures that the military will forever heed Party commands'\n",
    "\n",
    "\n",
    "    >>> round(single_meteor_score(reference1, hypothesis1),4)\n",
    "    0.7398\n",
    "\n",
    "        If there is no words match during the alignment the method returns the\n",
    "        score as 0. We can safely  return a zero instead of raising a\n",
    "        division by zero error as no match usually implies a bad translation.\n",
    "\n",
    "    >>> round(meteor_score('this is a cat', 'non matching hypothesis'),4)\n",
    "    0.0\n",
    "\n",
    "    :param references: reference sentences\n",
    "    :type references: list(str)\n",
    "    :param hypothesis: a hypothesis sentence\n",
    "    :type hypothesis: str\n",
    "    :param preprocess: preprocessing function (default str.lower)\n",
    "    :type preprocess: method\n",
    "    :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer())\n",
    "    :type stemmer: nltk.stem.api.StemmerI or any class that implements a stem method\n",
    "    :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet)\n",
    "    :type wordnet: WordNetCorpusReader\n",
    "    :param alpha: parameter for controlling relative weights of precision and recall.\n",
    "    :type alpha: float\n",
    "    :param beta: parameter for controlling shape of penalty as a\n",
    "                 function of as a function of fragmentation.\n",
    "    :type beta: float\n",
    "    :param gamma: relative weight assigned to fragmentation penality.\n",
    "    :type gamma: float\n",
    "    :return: The sentence-level METEOR score.\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    enum_hypothesis, enum_reference = _generate_enums(\n",
    "        hypothesis, reference, preprocess=preprocess\n",
    "    )\n",
    "    translation_length = len(enum_hypothesis)\n",
    "    reference_length = len(enum_reference)\n",
    "    matches, _, _ = _enum_allign_words(enum_hypothesis, enum_reference, stemmer=stemmer)\n",
    "    print(matches)\n",
    "    exact_m,_,_ = exact_match(hypothesis, reference)\n",
    "    print(exact_m)\n",
    "    stem_m,_,_ = _enum_stem_match(enum_hypothesis, enum_reference, stemmer=PorterStemmer())\n",
    "    print(stem_m)\n",
    "    syn_m,_,_ = _enum_wordnetsyn_match(enum_hypothesis, enum_reference, wordnet=wordnet)\n",
    "    print(syn_m)\n",
    "    \n",
    "    \n",
    "    \n",
    "    exact_count = len(exact_m)\n",
    "    stem_count = len((set(stem_m).difference(exact_m)))\n",
    "    syn_count = len((set(syn_m).difference(stem_m)))\n",
    "    print(exact_count)\n",
    "    matches_count = len(matches)\n",
    "    print(matches_count)\n",
    "    try:\n",
    "        precision = float(w_1*exact_count + w_2*stem_count + w_3*syn_count) / translation_length\n",
    "        recall = float(w_1*exact_count + w_2*stem_count + w_3*syn_count) / reference_length\n",
    "        #precision = float(matches_count) / translation_length\n",
    "        #recall = float(matches_count) / reference_length\n",
    "        fmean = (precision * recall) / (alpha * precision + (1 - alpha) * recall)\n",
    "        chunk_count = float(_count_chunks(matches))\n",
    "        frag_frac = chunk_count / matches_count\n",
    "    except ZeroDivisionError:\n",
    "        return 0.0\n",
    "    penalty = gamma * frag_frac ** beta\n",
    "    return (1 - penalty) * fmean\n",
    "\n",
    "\n",
    "\n",
    "def meteorn_score(\n",
    "    references,\n",
    "    hypothesis,\n",
    "    preprocess=str.lower,\n",
    "    stemmer=PorterStemmer(),\n",
    "    wordnet=wordnet,\n",
    "    alpha=0.85,\n",
    "    beta=2.35,\n",
    "    gamma=0.45,\n",
    "    w_1=1,\n",
    "    w_2=0.8,\n",
    "    w_3=0.6\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates METEOR score for hypothesis with multiple references as\n",
    "    described in \"Meteor: An Automatic Metric for MT Evaluation with\n",
    "    HighLevels of Correlation with Human Judgments\" by Alon Lavie and\n",
    "    Abhaya Agarwal, in Proceedings of ACL.\n",
    "    http://www.cs.cmu.edu/~alavie/METEOR/pdf/Lavie-Agarwal-2007-METEOR.pdf\n",
    "\n",
    "\n",
    "    In case of multiple references the best score is chosen. This method\n",
    "    iterates over single_meteor_score and picks the best pair among all\n",
    "    the references for a given hypothesis\n",
    "\n",
    "    >>> hypothesis1 = 'It is a guide to action which ensures that the military always obeys the commands of the party'\n",
    "    >>> hypothesis2 = 'It is to insure the troops forever hearing the activity guidebook that party direct'\n",
    "\n",
    "    >>> reference1 = 'It is a guide to action that ensures that the military will forever heed Party commands'\n",
    "    >>> reference2 = 'It is the guiding principle which guarantees the military forces always being under the command of the Party'\n",
    "    >>> reference3 = 'It is the practical guide for the army always to heed the directions of the party'\n",
    "\n",
    "    >>> round(meteor_score([reference1, reference2, reference3], hypothesis1),4)\n",
    "    0.7398\n",
    "\n",
    "        If there is no words match during the alignment the method returns the\n",
    "        score as 0. We can safely  return a zero instead of raising a\n",
    "        division by zero error as no match usually implies a bad translation.\n",
    "\n",
    "    >>> round(meteor_score(['this is a cat'], 'non matching hypothesis'),4)\n",
    "    0.0\n",
    "\n",
    "    :param references: reference sentences\n",
    "    :type references: list(str)\n",
    "    :param hypothesis: a hypothesis sentence\n",
    "    :type hypothesis: str\n",
    "    :param preprocess: preprocessing function (default str.lower)\n",
    "    :type preprocess: method\n",
    "    :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer())\n",
    "    :type stemmer: nltk.stem.api.StemmerI or any class that implements a stem method\n",
    "    :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet)\n",
    "    :type wordnet: WordNetCorpusReader\n",
    "    :param alpha: parameter for controlling relative weights of precision and recall.\n",
    "    :type alpha: float\n",
    "    :param beta: parameter for controlling shape of penalty as a function\n",
    "                 of as a function of fragmentation.\n",
    "    :type beta: float\n",
    "    :param gamma: relative weight assigned to fragmentation penality.\n",
    "    :type gamma: float\n",
    "    :return: The sentence-level METEOR score.\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    return max(\n",
    "        [\n",
    "            single_meteor_score(\n",
    "                reference,\n",
    "                hypothesis,\n",
    "                preprocess=preprocess,\n",
    "                stemmer=stemmer,\n",
    "                wordnet=wordnet,\n",
    "                alpha=alpha,\n",
    "                beta=beta,\n",
    "                gamma=gamma,\n",
    "            )\n",
    "            for reference in references\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b62a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorn=[]\n",
    "for i in range(len(auth_1)):\n",
    "    meteorn.append(round(meteorn_score([refs[i]],preds[i]),2))\n",
    "print(meteorn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff88515",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_mn = []\n",
    "\n",
    "max_mn=max(meteorn)\n",
    "min_mn=min(meteorn)\n",
    "\n",
    "for a in range(len(meteorn)):\n",
    "    norm_mn.append(round(((meteorn[a])/(max_mn)),2))\n",
    "print(norm_mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec89489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# calculate spearman's correlation\n",
    "coef, p = spearmanr(norm_mn, avg_norm_score)\n",
    "print('Spearmans correlation coefficient: %.3f' % coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "else:\n",
    "\tprint('correlated (reject H0) p=%.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16208641",
   "metadata": {},
   "source": [
    "# METEOR-NEXT with punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd14e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from itertools import chain, product\n",
    "\n",
    "\n",
    "def _generate_enums(hypothesis, reference, preprocess=str.lower):\n",
    "    \"\"\"\n",
    "    Takes in string inputs for hypothesis and reference and returns\n",
    "    enumerated word lists for each of them\n",
    "\n",
    "    :param hypothesis: hypothesis string\n",
    "    :type hypothesis: str\n",
    "    :param reference: reference string\n",
    "    :type reference: str\n",
    "    :preprocess: preprocessing method (default str.lower)\n",
    "    :type preprocess: method\n",
    "    :return: enumerated words list\n",
    "    :rtype: list of 2D tuples, list of 2D tuples\n",
    "    \"\"\"\n",
    "    hypothesis_list = list(enumerate(preprocess(hypothesis).split()))\n",
    "    reference_list = list(enumerate(preprocess(reference).split()))\n",
    "    return hypothesis_list, reference_list\n",
    "\n",
    "\n",
    "def exact_match(hypothesis, reference):\n",
    "    \"\"\"\n",
    "    matches exact words in hypothesis and reference\n",
    "    and returns a word mapping based on the enumerated\n",
    "    word id between hypothesis and reference\n",
    "\n",
    "    :param hypothesis: hypothesis string\n",
    "    :type hypothesis: str\n",
    "    :param reference: reference string\n",
    "    :type reference: str\n",
    "    :return: enumerated matched tuples, enumerated unmatched hypothesis tuples,\n",
    "             enumerated unmatched reference tuples\n",
    "    :rtype: list of 2D tuples, list of 2D tuples,  list of 2D tuples\n",
    "    \"\"\"\n",
    "    hypothesis_list, reference_list = _generate_enums(hypothesis, reference)\n",
    "    return _match_enums(hypothesis_list, reference_list)\n",
    "\n",
    "\n",
    "\n",
    "def _match_enums(enum_hypothesis_list, enum_reference_list):\n",
    "    \"\"\"\n",
    "    matches exact words in hypothesis and reference and returns\n",
    "    a word mapping between enum_hypothesis_list and enum_reference_list\n",
    "    based on the enumerated word id.\n",
    "\n",
    "    :param enum_hypothesis_list: enumerated hypothesis list\n",
    "    :type enum_hypothesis_list: list of tuples\n",
    "    :param enum_reference_list: enumerated reference list\n",
    "    :type enum_reference_list: list of 2D tuples\n",
    "    :return: enumerated matched tuples, enumerated unmatched hypothesis tuples,\n",
    "             enumerated unmatched reference tuples\n",
    "    :rtype: list of 2D tuples, list of 2D tuples,  list of 2D tuples\n",
    "    \"\"\"\n",
    "    word_match = []\n",
    "    for i in range(len(enum_hypothesis_list))[::-1]:\n",
    "        for j in range(len(enum_reference_list))[::-1]:\n",
    "            if enum_hypothesis_list[i][1] == enum_reference_list[j][1]:\n",
    "                word_match.append(\n",
    "                    (enum_hypothesis_list[i][0], enum_reference_list[j][0])\n",
    "                )\n",
    "                (enum_hypothesis_list.pop(i)[1], enum_reference_list.pop(j)[1])\n",
    "                break\n",
    "    return word_match, enum_hypothesis_list, enum_reference_list\n",
    "\n",
    "\n",
    "def _enum_stem_match(\n",
    "    enum_hypothesis_list, enum_reference_list, stemmer=PorterStemmer()\n",
    "):\n",
    "    \"\"\"\n",
    "    Stems each word and matches them in hypothesis and reference\n",
    "    and returns a word mapping between enum_hypothesis_list and\n",
    "    enum_reference_list based on the enumerated word id. The function also\n",
    "    returns a enumerated list of unmatched words for hypothesis and reference.\n",
    "\n",
    "    :param enum_hypothesis_list:\n",
    "    :type enum_hypothesis_list:\n",
    "    :param enum_reference_list:\n",
    "    :type enum_reference_list:\n",
    "    :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer())\n",
    "    :type stemmer: nltk.stem.api.StemmerI or any class that implements a stem method\n",
    "    :return: enumerated matched tuples, enumerated unmatched hypothesis tuples,\n",
    "             enumerated unmatched reference tuples\n",
    "    :rtype: list of 2D tuples, list of 2D tuples,  list of 2D tuples\n",
    "    \"\"\"\n",
    "    stemmed_enum_list1 = [\n",
    "        (word_pair[0], stemmer.stem(word_pair[1])) for word_pair in enum_hypothesis_list\n",
    "    ]\n",
    "\n",
    "    stemmed_enum_list2 = [\n",
    "        (word_pair[0], stemmer.stem(word_pair[1])) for word_pair in enum_reference_list\n",
    "    ]\n",
    "\n",
    "    word_match, enum_unmat_hypo_list, enum_unmat_ref_list = _match_enums(\n",
    "        stemmed_enum_list1, stemmed_enum_list2\n",
    "    )\n",
    "\n",
    "    enum_unmat_hypo_list = (\n",
    "        list(zip(*enum_unmat_hypo_list)) if len(enum_unmat_hypo_list) > 0 else []\n",
    "    )\n",
    "\n",
    "    enum_unmat_ref_list = (\n",
    "        list(zip(*enum_unmat_ref_list)) if len(enum_unmat_ref_list) > 0 else []\n",
    "    )\n",
    "\n",
    "    enum_hypothesis_list = list(\n",
    "        filter(lambda x: x[0] not in enum_unmat_hypo_list, enum_hypothesis_list)\n",
    "    )\n",
    "\n",
    "    enum_reference_list = list(\n",
    "        filter(lambda x: x[0] not in enum_unmat_ref_list, enum_reference_list)\n",
    "    )\n",
    "\n",
    "    return word_match, enum_hypothesis_list, enum_reference_list\n",
    "\n",
    "\n",
    "def stem_match(hypothesis, reference, stemmer=PorterStemmer()):\n",
    "    \"\"\"\n",
    "    Stems each word and matches them in hypothesis and reference\n",
    "    and returns a word mapping between hypothesis and reference\n",
    "\n",
    "    :param hypothesis:\n",
    "    :type hypothesis:\n",
    "    :param reference:\n",
    "    :type reference:\n",
    "    :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer())\n",
    "    :type stemmer: nltk.stem.api.StemmerI or any class that\n",
    "                   implements a stem method\n",
    "    :return: enumerated matched tuples, enumerated unmatched hypothesis tuples,\n",
    "             enumerated unmatched reference tuples\n",
    "    :rtype: list of 2D tuples, list of 2D tuples,  list of 2D tuples\n",
    "    \"\"\"\n",
    "    enum_hypothesis_list, enum_reference_list = _generate_enums(hypothesis, reference)\n",
    "    return _enum_stem_match(enum_hypothesis_list, enum_reference_list, stemmer=stemmer)\n",
    "\n",
    "\n",
    "\n",
    "def _enum_wordnetsyn_match(enum_hypothesis_list, enum_reference_list, wordnet=wordnet):\n",
    "    \"\"\"\n",
    "    Matches each word in reference to a word in hypothesis\n",
    "    if any synonym of a hypothesis word is the exact match\n",
    "    to the reference word.\n",
    "\n",
    "    :param enum_hypothesis_list: enumerated hypothesis list\n",
    "    :param enum_reference_list: enumerated reference list\n",
    "    :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet)\n",
    "    :type wordnet: WordNetCorpusReader\n",
    "    :return: list of matched tuples, unmatched hypothesis list, unmatched reference list\n",
    "    :rtype:  list of tuples, list of tuples, list of tuples\n",
    "\n",
    "    \"\"\"\n",
    "    word_match = []\n",
    "    for i in range(len(enum_hypothesis_list))[::-1]:\n",
    "        hypothesis_syns = set(\n",
    "            chain.from_iterable(\n",
    "                (\n",
    "                    lemma.name()\n",
    "                    for lemma in synset.lemmas()\n",
    "                    if lemma.name().find(\"_\") < 0\n",
    "                )\n",
    "                for synset in wordnet.synsets(enum_hypothesis_list[i][1])\n",
    "            )\n",
    "        ).union({enum_hypothesis_list[i][1]})\n",
    "        for j in range(len(enum_reference_list))[::-1]:\n",
    "            if enum_reference_list[j][1] in hypothesis_syns:\n",
    "                word_match.append(\n",
    "                    (enum_hypothesis_list[i][0], enum_reference_list[j][0])\n",
    "                )\n",
    "                enum_hypothesis_list.pop(i), enum_reference_list.pop(j)\n",
    "                break\n",
    "    return word_match, enum_hypothesis_list, enum_reference_list\n",
    "\n",
    "\n",
    "def wordnetsyn_match(hypothesis, reference, wordnet=wordnet):\n",
    "    \"\"\"\n",
    "    Matches each word in reference to a word in hypothesis if any synonym\n",
    "    of a hypothesis word is the exact match to the reference word.\n",
    "\n",
    "    :param hypothesis: hypothesis string\n",
    "    :param reference: reference string\n",
    "    :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet)\n",
    "    :type wordnet: WordNetCorpusReader\n",
    "    :return: list of mapped tuples\n",
    "    :rtype: list of tuples\n",
    "    \"\"\"\n",
    "    enum_hypothesis_list, enum_reference_list = _generate_enums(hypothesis, reference)\n",
    "    return _enum_wordnetsyn_match(\n",
    "        enum_hypothesis_list, enum_reference_list, wordnet=wordnet\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def _enum_allign_words(\n",
    "    enum_hypothesis_list, enum_reference_list, stemmer=PorterStemmer(), wordnet=wordnet\n",
    "):\n",
    "    \"\"\"\n",
    "    Aligns/matches words in the hypothesis to reference by sequentially\n",
    "    applying exact match, stemmed match and wordnet based synonym match.\n",
    "    in case there are multiple matches the match which has the least number\n",
    "    of crossing is chosen. Takes enumerated list as input instead of\n",
    "    string input\n",
    "\n",
    "    :param enum_hypothesis_list: enumerated hypothesis list\n",
    "    :param enum_reference_list: enumerated reference list\n",
    "    :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer())\n",
    "    :type stemmer: nltk.stem.api.StemmerI or any class that implements a stem method\n",
    "    :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet)\n",
    "    :type wordnet: WordNetCorpusReader\n",
    "    :return: sorted list of matched tuples, unmatched hypothesis list,\n",
    "             unmatched reference list\n",
    "    :rtype: list of tuples, list of tuples, list of tuples\n",
    "    \"\"\"\n",
    "    exact_matches, enum_hypothesis_list, enum_reference_list = _match_enums(\n",
    "        enum_hypothesis_list, enum_reference_list\n",
    "    )\n",
    "\n",
    "    stem_matches, enum_hypothesis_list, enum_reference_list = _enum_stem_match(\n",
    "        enum_hypothesis_list, enum_reference_list, stemmer=stemmer\n",
    "    )\n",
    "\n",
    "    wns_matches, enum_hypothesis_list, enum_reference_list = _enum_wordnetsyn_match(\n",
    "        enum_hypothesis_list, enum_reference_list, wordnet=wordnet\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        sorted(\n",
    "            exact_matches + stem_matches + wns_matches, key=lambda wordpair: wordpair[0]\n",
    "        ),\n",
    "        enum_hypothesis_list,\n",
    "        enum_reference_list,\n",
    "    )\n",
    "\n",
    "\n",
    "def allign_words(hypothesis, reference, stemmer=PorterStemmer(), wordnet=wordnet):\n",
    "    \"\"\"\n",
    "    Aligns/matches words in the hypothesis to reference by sequentially\n",
    "    applying exact match, stemmed match and wordnet based synonym match.\n",
    "    In case there are multiple matches the match which has the least number\n",
    "    of crossing is chosen.\n",
    "\n",
    "    :param hypothesis: hypothesis string\n",
    "    :param reference: reference string\n",
    "    :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer())\n",
    "    :type stemmer: nltk.stem.api.StemmerI or any class that implements a stem method\n",
    "    :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet)\n",
    "    :type wordnet: WordNetCorpusReader\n",
    "    :return: sorted list of matched tuples, unmatched hypothesis list, unmatched reference list\n",
    "    :rtype: list of tuples, list of tuples, list of tuples\n",
    "    \"\"\"\n",
    "    enum_hypothesis_list, enum_reference_list = _generate_enums(hypothesis, reference)\n",
    "    return _enum_allign_words(\n",
    "        enum_hypothesis_list, enum_reference_list, stemmer=stemmer, wordnet=wordnet\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def _count_chunks(matches):\n",
    "    \"\"\"\n",
    "    Counts the fewest possible number of chunks such that matched unigrams\n",
    "    of each chunk are adjacent to each other. This is used to caluclate the\n",
    "    fragmentation part of the metric.\n",
    "\n",
    "    :param matches: list containing a mapping of matched words (output of allign_words)\n",
    "    :return: Number of chunks a sentence is divided into post allignment\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    chunks = 1\n",
    "    while i < len(matches) - 1:\n",
    "        if (matches[i + 1][0] == matches[i][0] + 1) and (\n",
    "            matches[i + 1][1] == matches[i][1] + 1\n",
    "        ):\n",
    "            i += 1\n",
    "            continue\n",
    "        i += 1\n",
    "        chunks += 1\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def single_meteor_score(\n",
    "    reference,\n",
    "    hypothesis,\n",
    "    preprocess=str.lower,\n",
    "    stemmer=PorterStemmer(),\n",
    "    wordnet=wordnet,\n",
    "    alpha=0.85,\n",
    "    beta=2.35,\n",
    "    gamma=0.45,\n",
    "    w_1=1,\n",
    "    w_2=0.8,\n",
    "    w_3=0.6\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates METEOR score for single hypothesis and reference as per\n",
    "    \"Meteor: An Automatic Metric for MT Evaluation with HighLevels of\n",
    "    Correlation with Human Judgments\" by Alon Lavie and Abhaya Agarwal,\n",
    "    in Proceedings of ACL.\n",
    "    http://www.cs.cmu.edu/~alavie/METEOR/pdf/Lavie-Agarwal-2007-METEOR.pdf\n",
    "\n",
    "\n",
    "    >>> hypothesis1 = 'It is a guide to action which ensures that the military always obeys the commands of the party'\n",
    "\n",
    "    >>> reference1 = 'It is a guide to action that ensures that the military will forever heed Party commands'\n",
    "\n",
    "\n",
    "    >>> round(single_meteor_score(reference1, hypothesis1),4)\n",
    "    0.7398\n",
    "\n",
    "        If there is no words match during the alignment the method returns the\n",
    "        score as 0. We can safely  return a zero instead of raising a\n",
    "        division by zero error as no match usually implies a bad translation.\n",
    "\n",
    "    >>> round(meteor_score('this is a cat', 'non matching hypothesis'),4)\n",
    "    0.0\n",
    "\n",
    "    :param references: reference sentences\n",
    "    :type references: list(str)\n",
    "    :param hypothesis: a hypothesis sentence\n",
    "    :type hypothesis: str\n",
    "    :param preprocess: preprocessing function (default str.lower)\n",
    "    :type preprocess: method\n",
    "    :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer())\n",
    "    :type stemmer: nltk.stem.api.StemmerI or any class that implements a stem method\n",
    "    :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet)\n",
    "    :type wordnet: WordNetCorpusReader\n",
    "    :param alpha: parameter for controlling relative weights of precision and recall.\n",
    "    :type alpha: float\n",
    "    :param beta: parameter for controlling shape of penalty as a\n",
    "                 function of as a function of fragmentation.\n",
    "    :type beta: float\n",
    "    :param gamma: relative weight assigned to fragmentation penality.\n",
    "    :type gamma: float\n",
    "    :return: The sentence-level METEOR score.\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    enum_hypothesis, enum_reference = _generate_enums(\n",
    "        hypothesis, reference, preprocess=preprocess\n",
    "    )\n",
    "    translation_length = len(enum_hypothesis)\n",
    "    reference_length = len(enum_reference)\n",
    "    matches, _, _ = _enum_allign_words(enum_hypothesis, enum_reference, stemmer=stemmer)\n",
    "    print(matches)\n",
    "    exact_m,_,_ = exact_match(hypothesis, reference)\n",
    "    print(exact_m)\n",
    "    stem_m,_,_ = _enum_stem_match(enum_hypothesis, enum_reference, stemmer=PorterStemmer())\n",
    "    print(stem_m)\n",
    "    syn_m,_,_ = _enum_wordnetsyn_match(enum_hypothesis, enum_reference, wordnet=wordnet)\n",
    "    print(syn_m)\n",
    "    \n",
    "    \n",
    "    \n",
    "    exact_count = len(exact_m)\n",
    "    stem_count = len((set(stem_m).difference(exact_m)))\n",
    "    syn_count = len((set(syn_m).difference(stem_m)))\n",
    "    print(exact_count)\n",
    "    matches_count = len(matches)\n",
    "    print(matches_count)\n",
    "    try:\n",
    "        precision = float(w_1*exact_count + w_2*stem_count + w_3*syn_count) / translation_length\n",
    "        recall = float(w_1*exact_count + w_2*stem_count + w_3*syn_count) / reference_length\n",
    "        #precision = float(matches_count) / translation_length\n",
    "        #recall = float(matches_count) / reference_length\n",
    "        fmean = (precision * recall) / (alpha * precision + (1 - alpha) * recall)\n",
    "        chunk_count = float(_count_chunks(matches))\n",
    "        frag_frac = chunk_count / matches_count\n",
    "    except ZeroDivisionError:\n",
    "        return 0.0\n",
    "    penalty = gamma * frag_frac ** beta\n",
    "    return (1 - penalty) * fmean\n",
    "\n",
    "\n",
    "\n",
    "def meteorn_score(\n",
    "    references,\n",
    "    hypothesis,\n",
    "    preprocess=str.lower,\n",
    "    stemmer=PorterStemmer(),\n",
    "    wordnet=wordnet,\n",
    "    alpha=0.85,\n",
    "    beta=2.35,\n",
    "    gamma=0.45,\n",
    "    w_1=1,\n",
    "    w_2=0.8,\n",
    "    w_3=0.6\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates METEOR score for hypothesis with multiple references as\n",
    "    described in \"Meteor: An Automatic Metric for MT Evaluation with\n",
    "    HighLevels of Correlation with Human Judgments\" by Alon Lavie and\n",
    "    Abhaya Agarwal, in Proceedings of ACL.\n",
    "    http://www.cs.cmu.edu/~alavie/METEOR/pdf/Lavie-Agarwal-2007-METEOR.pdf\n",
    "\n",
    "\n",
    "    In case of multiple references the best score is chosen. This method\n",
    "    iterates over single_meteor_score and picks the best pair among all\n",
    "    the references for a given hypothesis\n",
    "\n",
    "    >>> hypothesis1 = 'It is a guide to action which ensures that the military always obeys the commands of the party'\n",
    "    >>> hypothesis2 = 'It is to insure the troops forever hearing the activity guidebook that party direct'\n",
    "\n",
    "    >>> reference1 = 'It is a guide to action that ensures that the military will forever heed Party commands'\n",
    "    >>> reference2 = 'It is the guiding principle which guarantees the military forces always being under the command of the Party'\n",
    "    >>> reference3 = 'It is the practical guide for the army always to heed the directions of the party'\n",
    "\n",
    "    >>> round(meteor_score([reference1, reference2, reference3], hypothesis1),4)\n",
    "    0.7398\n",
    "\n",
    "        If there is no words match during the alignment the method returns the\n",
    "        score as 0. We can safely  return a zero instead of raising a\n",
    "        division by zero error as no match usually implies a bad translation.\n",
    "\n",
    "    >>> round(meteor_score(['this is a cat'], 'non matching hypothesis'),4)\n",
    "    0.0\n",
    "\n",
    "    :param references: reference sentences\n",
    "    :type references: list(str)\n",
    "    :param hypothesis: a hypothesis sentence\n",
    "    :type hypothesis: str\n",
    "    :param preprocess: preprocessing function (default str.lower)\n",
    "    :type preprocess: method\n",
    "    :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer())\n",
    "    :type stemmer: nltk.stem.api.StemmerI or any class that implements a stem method\n",
    "    :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet)\n",
    "    :type wordnet: WordNetCorpusReader\n",
    "    :param alpha: parameter for controlling relative weights of precision and recall.\n",
    "    :type alpha: float\n",
    "    :param beta: parameter for controlling shape of penalty as a function\n",
    "                 of as a function of fragmentation.\n",
    "    :type beta: float\n",
    "    :param gamma: relative weight assigned to fragmentation penality.\n",
    "    :type gamma: float\n",
    "    :return: The sentence-level METEOR score.\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    return max(\n",
    "        [\n",
    "            single_meteor_score(\n",
    "                reference,\n",
    "                hypothesis,\n",
    "                preprocess=preprocess,\n",
    "                stemmer=stemmer,\n",
    "                wordnet=wordnet,\n",
    "                alpha=alpha,\n",
    "                beta=beta,\n",
    "                gamma=gamma,\n",
    "            )\n",
    "            for reference in references\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf70ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorn_pr=[]\n",
    "for i in range(len(auth_1)):\n",
    "    meteorn_pr.append(round(meteorn_score([refs_n[i]],preds_n[i]),2))\n",
    "print(meteorn_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51270fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_mn_pr = []\n",
    "\n",
    "max_mn=max(meteorn_pr)\n",
    "min_mn=min(meteorn_pr)\n",
    "\n",
    "for a in range(len(meteorn_pr)):\n",
    "    norm_mn_pr.append(round(((meteorn_pr[a])/(max_mn)),2))\n",
    "print(norm_mn_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d15bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# calculate spearman's correlation\n",
    "coef, p = spearmanr(norm_mn_pr, avg_norm_score)\n",
    "print('Spearmans correlation coefficient: %.3f' % coef)\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "else:\n",
    "\tprint('correlated (reject H0) p=%.3f' % p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
